{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from math import *\n",
    "from utils import *\n",
    "import time\n",
    "import itertools\n",
    "import csv\n",
    "colors = ['BLACK', 'RED', 'MAROON', 'YELLOW','OLIVE','AQUA','LIME','GREEN','TEAL']\n",
    "markers=['3','4','8','s','p','P','o','v','^','<','*','h','H','+','x','X','D','d','|','_']\n",
    "style=itertools.cycle([\"-\",\"--\",\"-.\",\":\",\"None\",\"\",\" \",\"-\",\"--\",\"-.\",\":\"])\n",
    "markers=['4','<','8','s','p','P','o','v','^','<','*','h','H','+','x','X','D','d','|','_']\n",
    "descriptions=['point', 'pixel', 'circle', 'triangle_down', 'tri_down', 'octagon', 'square', 'pentagon', 'plus (filled)','star', 'hexagon1', 'hexagon2', 'plus', 'x', 'x (filled)','diamond', 'thin_diamond', 'vline', 'hline']\n",
    "csfont = {'fontname':'Times New Roman'}\n",
    "\n",
    "# geometric distribution for trials prob(n) = p q^(n-1) where p is success probability\n",
    "# F_geo = lambda x,p: np.floor(np.log(1-x)/np.log(1-p))\n",
    "# f = lambda x,p: p* (1-p)**(x-1)\n",
    "# # photon transmission probability in fiber (i.e., 0.2dB/km)\n",
    "# Trans = lambda x: 10**(-0.2*x/10)\n",
    "# # Binary Shanon entropy\n",
    "# def h(p_list):\n",
    "#     y_list = np.zeros(len(p_list))\n",
    "#     for i,p in enumerate(p_list):\n",
    "#         if p<1e-6 or (1-p)<1e-6:\n",
    "#             y_list[i]= 0\n",
    "#         else:\n",
    "#             y_list[i]= -p*np.log2(p)-(1-p)*np.log2(1-p)\n",
    "#     return y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_plotting_global_attributes(x_axis_label,y_axis_label,x_axis_font_size,\n",
    "                                   y_axis_font_size,x_axis_tick_font_size,\n",
    "                                   y_axis_tick_font_size,x_axis_pad,y_axis_pad,\n",
    "                                  image_width,image_lenght):\n",
    "    import matplotlib.pyplot as plt\n",
    "    global global_font_size\n",
    "    global figure_width\n",
    "    global figure_highth\n",
    "    global space_from_x_y_axis\n",
    "    global style\n",
    "    global markers\n",
    "    global csfont\n",
    "    global descriptions\n",
    "    font_size = 44\n",
    "#     plt.figure(figsize=(10,0))\n",
    "    global fig\n",
    "    global global_mark_every\n",
    "    global_mark_every = 1\n",
    "    #matplotlib.rcParams['text.usetex'] = True\n",
    "    fig = plt.figure()\n",
    "    if image_width==0:\n",
    "        image_width = 5.6\n",
    "        image_lenght = 3.8\n",
    "    fig.set_size_inches(image_width, image_lenght, forward=True)# default \n",
    "#     fig.set_size_inches(14, 8)\n",
    "#     fig.set_size_inches(8, 6)\n",
    "    global style\n",
    "    #matplotlib.rcParams['text.usetex'] = True\n",
    "    global markers\n",
    "    \n",
    "    global descriptions\n",
    "\n",
    "    label_size = 40\n",
    "    #matplotlib.rcParams['text.usetex'] = True\n",
    "    csfont = {'fontname':'Times New Roman'}\n",
    "    #write your code related to basemap here\n",
    "    #plt.title('title',**csfont)\n",
    "    plt.rcParams['xtick.labelsize'] = x_axis_tick_font_size \n",
    "    #matplotlib.rcParams['text.usetex'] = True\n",
    "    plt.rcParams['ytick.labelsize']= y_axis_tick_font_size\n",
    "    #matplotlib.rcParams['text.usetex'] = True\n",
    "    plt.xlabel(x_axis_label, fontsize=x_axis_font_size,labelpad=x_axis_pad)\n",
    "    #matplotlib.rcParams['text.usetex'] = True\n",
    "    plt.ylabel(y_axis_label,fontsize=y_axis_font_size,labelpad=y_axis_pad)\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    #matplotlib.rcParams['text.usetex'] = True\n",
    "    #plt.ylim(ymin=0) \n",
    "    return plt\n",
    "def ploting_simple_y_as_x(x_axix_label,y_axix_label,\n",
    "                          x_axis_font_size, y_axis_font_size, x_axis_tick_font_size,\n",
    "                          y_axis_tick_font_size, x_axis_pad, y_axis_pad,\n",
    "                          x_min_value,y_axis_provided_min_value,tick_flag,xticks_points,\n",
    "                          y_axis_provided_max_value,\n",
    "                          dictionary_keys_in_order,legends_titles,passed_colors,passed_lines,\n",
    "                          each_scheme_each_step_value,\n",
    "                          x_axis_points,tickets_on_x_axis,\n",
    "                          log_scale,x_axis_log_scal_flag,legend_flag,\n",
    "                          print_flag,legend_num_column,\n",
    "                          legend_font_size,plot_name,\n",
    "                          having_mark_on_linkes_flag,given_marker_size,image_width,plot_height,\n",
    "                         legends_on_the_right_flag):\n",
    "    \n",
    " \n",
    "    colors = ['C0',\"C1\",'C2','C3','C4','C5',\"C6\",\"C6\",\"C6\",\"C6\",\"C6\"]\n",
    "    style=[ 'solid', 'dashed','solid', 'dashed', 'solid', 'dashed','solid', 'dashed','solid', 'dashed']\n",
    "    plt = set_plotting_global_attributes(x_axix_label,y_axix_label,x_axis_font_size, \n",
    "                          y_axis_font_size, x_axis_tick_font_size,\n",
    "                          y_axis_tick_font_size, x_axis_pad, y_axis_pad,\n",
    "                                         image_width,plot_height)\n",
    "                        \n",
    "            \n",
    "    #print Read_and_Detection_time_with_convergence_Det_Alg\n",
    "    my_dic = {}\n",
    "\n",
    "\n",
    "    my_class_labels = []\n",
    "\n",
    "    \n",
    "#     x = np.arange(len(topologies))\n",
    "    x = np.arange(max(x_axis_points))\n",
    "    x = []\n",
    "    for point_x_axis in x_axis_points:\n",
    "        x.append((point_x_axis))\n",
    "    x.sort()\n",
    "    #print('we have %s as our x '%(x))\n",
    "    sizes = []\n",
    "    #plt.gca().set_color_cycle(['BLACK', 'RED', 'MAROON', 'YELLOW','OLIVE','LIME','GREEN','AQUA','TEAL'])\n",
    "\n",
    "\n",
    "    index = 0\n",
    "    color_index =0\n",
    "    for scheme_key in dictionary_keys_in_order:\n",
    "        label_of_result = scheme_key\n",
    "        y_axis_values = []\n",
    "        import math\n",
    "        from math import log\n",
    "        x_values_for_this_scheme = []\n",
    "        for point in x_axis_points:\n",
    "            try:\n",
    "                value  = each_scheme_each_step_value[scheme_key][point]\n",
    "                if print_flag:\n",
    "                    print(\"we get the values for scheme %s point %s %s\"%(scheme_key,point,value))            \n",
    "                y_axis_values.append(value)\n",
    "                x_values_for_this_scheme.append(point)\n",
    "            except:\n",
    "                pass\n",
    "        sizes.append(str(scheme_key))\n",
    "        #print(\"these are the x and y axis values\",Convergence_times,label_of_result)\n",
    "        if having_mark_on_linkes_flag:\n",
    "            if scheme_key in legends_titles:\n",
    "                plt.plot(x_values_for_this_scheme, y_axis_values,passed_colors[color_index],\n",
    "                     linestyle=passed_lines[index],markevery=(0.0,0.1),linewidth=2.0,\n",
    "                     markersize=given_marker_size,markerfacecolor='black',markeredgewidth='2', \n",
    "                     markeredgecolor=colors[color_index],label = scheme_key)\n",
    "            else:\n",
    "                plt.plot(x_values_for_this_scheme, y_axis_values,passed_colors[color_index],\n",
    "                     linestyle=passed_lines[index],markevery=(0.0,0.1),linewidth=2.0,\n",
    "                     markersize=given_marker_size,markerfacecolor='black',markeredgewidth='2', \n",
    "                     markeredgecolor=colors[color_index])\n",
    "                \n",
    "        else:\n",
    "            plt.plot(x_values_for_this_scheme, y_axis_values,passed_colors[color_index],\n",
    "                 linestyle=passed_lines[index],markevery=(0.0,0.1),linewidth=2.0)\n",
    "            \n",
    "#         print(\"scheme %s x points %s      \"%(scheme_key,x))\n",
    "#         print(\"scheme %s y_axis points %s \"%(scheme_key,y_axis_values))\n",
    "        index = index +1\n",
    "        color_index+=1\n",
    "        # if color_index >=len(colors):\n",
    "        #     color_index = 1\n",
    "        # if index >= len(style):\n",
    "        #     index = 2\n",
    "    my_class_labels = sizes\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.xlim(xmin=min(x_axis_points),xmax = max(x_axis_points))\n",
    "\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.grid(which='minor', linestyle=':', linewidth='0.1', color='black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if log_scale:\n",
    "        plt.yscale('log')\n",
    "    if legend_flag:\n",
    "        plt.legend([label for label in legends_titles ],handlelength=1.0,fontsize=legend_font_size, \n",
    "                   ncol=legend_num_column,handleheight=2.4, labelspacing=0.02)\n",
    "\n",
    "    if legends_on_the_right_flag:\n",
    "        ax = plt.subplot(111)\n",
    "        ax.legend([label for label in legends_titles ],handlelength=1.0,\n",
    "                  fontsize=legend_font_size,loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        # ax.xticks(np.arange(min(x_values_for_this_scheme), max(x_values_for_this_scheme)+1, 0.1))\n",
    "    plt.ylim(y_axis_provided_min_value, y_axis_provided_max_value)\n",
    "    plt.minorticks_on()\n",
    "    plt.legend(fontsize=legend_font_size,handlelength=1.0,bbox_to_anchor=(0.36, 0.43))\n",
    "\n",
    "    plt.grid(which='minor', linestyle=':', linewidth='0.2', color='black')\n",
    "    if x_axis_log_scal_flag:\n",
    "        plt.xscale(\"log\")\n",
    "    # start, end = ax.get_xlim()\n",
    "    # ax.xaxis.set_ticks(np.arange(start, end, 0.1))\n",
    "    # plt.xticks(np.arange(0, 1, 20)) \n",
    "    plt.grid( which='minor', color='#999999', linestyle='-', alpha=0.1)\n",
    "    # plt.xticks(np.arange(min(x_values_for_this_scheme), x_max_value, x_axis_tick_frequency))\n",
    "    if tick_flag:\n",
    "        ax = plt.subplot(111)\n",
    "        ax.set_xticks(xticks_points)\n",
    "    # plt.set_xticks([0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])\n",
    "    plt.tight_layout()\n",
    "    plt.grid(which='minor', linestyle=':', linewidth='0.2', color='black')\n",
    "    # plt.locator_params(axis='both', nbins=10)\n",
    "    plt.savefig(plot_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# no cutoff\n",
    "For reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "c = 2e5 # speed of light in fiber [km/s]\n",
    "p_link = 1.0 # photon insertion loss incorporates various efficiencies of the experimental hardware\n",
    "\n",
    "# def T_sequential_no_cutoff(τ_coh, mu_link, F_link,links):\n",
    "#     \"\"\" Calculate performance metrics for asynchronous sequential scheme using analytical formulas\n",
    "#     inputs:\n",
    "#         τ_coh: coherence time of quantum memories\n",
    "#         mu_link: parameter in 2qubit depolarizing channel describing noisy link-level entanglement and\n",
    "#         entanglement swapping error\n",
    "#         F_link: fidelity of link level entanglement (i.e.,quality of locally generated Bell pairs)\n",
    "#         links: list of segment (link) lengths in km\n",
    "#     outputs:\n",
    "#         Raw_rate: 1/ expected value of total time for e2e entanglement delivery\n",
    "#         *** application specific quantities:\n",
    "#         skr: secret key rate for qkd (does not include idle times of end memories)\n",
    "#         F_e2e: e2e entanglement fidelity for entanglement distrubtion (does include idle times of end memories)\n",
    "#     \"\"\"\n",
    "#     if type(links) != np.ndarray:\n",
    "#         links = np.array(links)\n",
    "#     τs = links/c\n",
    "#     T_tot = 2* np.sum( τs / (p_link*Trans(links)) )\n",
    "\n",
    "#     raw_rate = 1/T_tot\n",
    "#     N_links = len(links) # number of links, i.e. no. of repeaters + 1\n",
    "#     mu_e2e = mu_link**(2*N_links-1)\n",
    "#     # secret key rate calculations\n",
    "#     f_memory_qkd = np.prod( p_link*Trans(links[1:])*np.exp(-4*τs[1:]/τ_coh)/(1- (1-p_link*Trans(links[1:]))*np.exp(-2*τs[1:]/τ_coh) )  )\n",
    "#     f_e2e_qkd = 0.5 + 0.5 * (2*F_link-1)**N_links *f_memory_qkd\n",
    "#     ex = (1 - mu_e2e)/2\n",
    "#     ez = (1 + mu_e2e)/2 - mu_e2e * f_e2e_qkd\n",
    "#     skr = raw_rate * (1-h([ex])-h([ez]))\n",
    "#     #  fidelity of e2e Bell pairs\n",
    "#     Le2e = np.sum(links)\n",
    "#     τe2e = Le2e/c\n",
    "#     f_memory_bell = np.exp(-3*τe2e/τ_coh) *np.prod(p_link*Trans(links[1:])*np.exp(-4*τs[1:]/τ_coh)/(1- (1-p_link*Trans(links[1:]))*np.exp(-4*τs[1:]/τ_coh) ) )\n",
    "#     f_e2e_bell = 0.5 + 0.5 * (2*F_link-1)**N_links *f_memory_bell\n",
    "#     F_e2e = mu_e2e * f_e2e_bell + (1-mu_e2e)/4\n",
    "\n",
    "#     return raw_rate, skr, F_e2e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with cutoff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "c = 2e5 # speed of light in fiber [km/s]\n",
    "p_link = 1.0 # photon insertion loss incorporates various efficiencies of the experimental hardware\n",
    "\n",
    "\n",
    "# def T_sequential_cutoff(τ_cut,τ_coh, mu_link, F_link,links):\n",
    "#     \"\"\" Calculate performance metrics for asynchronous sequential scheme using analytical formulas\n",
    "#     inputs:\n",
    "#         τ_cut: cut-off time\n",
    "#         τ_coh: coherence time of quantum memories\n",
    "#         mu_link: parameter in 2qubit depolarizing channel describing noisy link-level entanglement and\n",
    "#         entanglement swapping error\n",
    "#         F_link: fidelity of link level entanglement (i.e.,quality of locally generated Bell pairs)\n",
    "#         links: list of segment (link) lengths in km\n",
    "#     outputs:\n",
    "#         Raw_rate: 1/ expected value of total time for e2e entanglement delivery\n",
    "#         *** application specific quantities:\n",
    "#         skr: secret key rate for qkd (does not include idle times of end memories)\n",
    "#         F_e2e: e2e entanglement fidelity for entanglement distrubtion (does include idle times of end memories)\n",
    "#     \"\"\"\n",
    "#     if type(links) != np.ndarray:\n",
    "#         links = np.array(links)\n",
    "#     τs = links/c\n",
    "#     # implementing the recursion relation :\n",
    "#     ### Tn = Tn-1 / Pn + ( (1/Pn -1) τ_cut + Nm(ms[n],ps[n])*2*τs[n]/Pn)\n",
    "#     p1 = p_link*Trans(links[0])\n",
    "#     T_tot = 2*τs[0]/p1\n",
    "#     for i_l in np.arange(1,len(links)):\n",
    "#         L = links[i_l]\n",
    "#         m_n = int(τ_cut/(2*τs[i_l]))\n",
    "#         p_n = p_link*Trans(L)\n",
    "#         Nm = lambda x: (1-(1+m_n*x)*(1-x)**m_n)/x\n",
    "#         Pm = 1- (1-p_n)**m_n\n",
    "#         T_tot = T_tot / Pm +  (1/Pm -1)*τ_cut + Nm(p_n)*2*τs[i_l]/Pm\n",
    "\n",
    "#     raw_rate = 1/T_tot\n",
    "#     N_links = len(links) # number of links, i.e. no. of repeaters + 1\n",
    "#     mu_e2e = mu_link**(2*N_links-1)\n",
    "#     # secret key rate calculations\n",
    "#     m_arr = np.floor(τ_cut/(2*τs))\n",
    "#     Pm_arr = 1- (1-p_link*Trans(links))**m_arr\n",
    "#     f_memory_qkd = np.prod( p_link*Trans(links[1:])/Pm_arr[1:] * np.exp(-4*τs[1:]/τ_coh) * (1- (1-p_link*Trans(links[1:]))**m_arr[1:] *np.exp(-2*m_arr[1:]*τs[1:]/τ_coh) )  /(1- (1-p_link*Trans(links[1:]))*np.exp(-2*τs[1:]/τ_coh) )  )\n",
    "#     f_e2e_qkd = 0.5 + 0.5 * (2*F_link-1)**N_links *f_memory_qkd\n",
    "#     ex = (1 - mu_e2e)/2\n",
    "#     ez = (1 + mu_e2e)/2 - mu_e2e * f_e2e_qkd\n",
    "#     skr = raw_rate * (1-h([ex])-h([ez]))\n",
    "#     #  fidelity of e2e Bell pairs\n",
    "#     Le2e = np.sum(links)\n",
    "#     τe2e = Le2e/c\n",
    "#     f_memory_bell = np.exp(-3*τe2e/τ_coh) *np.prod( p_link*Trans(links[1:])/Pm_arr[1:] * np.exp(-4*τs[1:]/τ_coh) * (1- (1-p_link*Trans(links[1:]))**m_arr[1:] *np.exp(-4*m_arr[1:]*τs[1:]/τ_coh) )  /(1- (1-p_link*Trans(links[1:]))*np.exp(-4*τs[1:]/τ_coh) )  )\n",
    "#     f_e2e_bell = 0.5 + 0.5 * (2*F_link-1)**N_links *f_memory_bell\n",
    "#     F_e2e = mu_e2e * f_e2e_bell + (1-mu_e2e)/4\n",
    "\n",
    "#     # skr, F_e2e = 0, 0\n",
    "#     return raw_rate, skr, F_e2e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimal cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_L 0 Le2e 1.0 F_link 1.0 mu_link 1.0 took 1.3311703999837239e-06 minutes\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_L 42 Le2e 170.27272727272728 F_link 1.0 mu_link 0.99 took 1.415944266319275 minutess\r"
     ]
    }
   ],
   "source": [
    "each_scheme_scheme_point_value = {}\n",
    "selected_scheme_keys = []\n",
    "\n",
    "parallel_scheme_flag = True\n",
    "sequential_scheme = False\n",
    "parallel_with_cutoff_flag = True\n",
    "for F_link in [1.0,0.95,0.9]:#F_link = 1 # fidelity of local BP\n",
    "    for mu_link in [1.0,0.99]:#mu_link = 1 # depolarizing noise channel parameter (1: no noise, 0: fully depolarized)\n",
    "        n = 8 # number of segments (i.e., no. of repeaters -1 )\n",
    "        # τ_coh_list = np.logspace(-4,1,40) # coherence time [sec]\n",
    "        τ_coh_list = np.logspace(-4,-2,30) # coherence time [sec]\n",
    "        # τ_coh_list = np.logspace(-4,-2,10) # coherence time [sec]\n",
    "        Le2e_list = np.linspace(1,400,100)\n",
    "        # Le2e_list = np.linspace(1,400,4)\n",
    "        start_time = time.time()\n",
    "        num_τ = 200\n",
    "        num_τ = 50\n",
    "        raw_rate_seq = np.zeros((len(Le2e_list),len(τ_coh_list),num_τ))\n",
    "        skr_seq = np.zeros((len(Le2e_list),len(τ_coh_list),num_τ))\n",
    "        Fe2e_seq = np.zeros((len(Le2e_list),len(τ_coh_list),num_τ))\n",
    "        \n",
    "        skr_seq_opt = np.zeros((len(Le2e_list),len(τ_coh_list)))\n",
    "        raw_rate_seq_opt = np.zeros((len(Le2e_list),len(τ_coh_list)))\n",
    "        Fe2e_seq_opt = np.zeros((len(Le2e_list),len(τ_coh_list)))\n",
    "        τ_cut_opt =  np.zeros((len(Le2e_list),len(τ_coh_list)))\n",
    "        skr_seq_no_cut =  np.zeros((len(Le2e_list),len(τ_coh_list)))\n",
    "\n",
    "        raw_rate_par = np.zeros((len(Le2e_list),len(τ_coh_list),num_τ))\n",
    "        skr_par = np.zeros((len(Le2e_list),len(τ_coh_list),num_τ))\n",
    "        Fe2e_par = np.zeros((len(Le2e_list),len(τ_coh_list),num_τ))\n",
    "        \n",
    "        skr_par_opt = np.zeros((len(Le2e_list),len(τ_coh_list)))\n",
    "        raw_rate_par_opt = np.zeros((len(Le2e_list),len(τ_coh_list)))\n",
    "        Fe2e_par_opt = np.zeros((len(Le2e_list),len(τ_coh_list)))\n",
    "        τ_cut_opt =  np.zeros((len(Le2e_list),len(τ_coh_list)))\n",
    "        skr_par_no_cut =  np.zeros((len(Le2e_list),len(τ_coh_list)))\n",
    "\n",
    "\n",
    "        \n",
    "        start_time_L = time.time()\n",
    "        for i_L, Le2e in enumerate(Le2e_list):\n",
    "            Ls = [Le2e/n]*n\n",
    "            τ_cut_list = np.logspace(-0.5,2,num_τ)*Ls[0]/c/2 # cutoff [sec]\n",
    "            end_time_L = time.time()\n",
    "            duration = end_time_L-start_time_L\n",
    "            print(\"i_L %s Le2e %s F_link %s mu_link %s took %s minutes\"%(i_L,Le2e,F_link,mu_link,duration/60),end= \"\\r\")\n",
    "            \n",
    "            start_time_L = time.time()\n",
    "            for i_coh, τ_coh in enumerate(τ_coh_list):\n",
    "                for i_t, τ_cut in enumerate(τ_cut_list):\n",
    "                    if sequential_scheme:\n",
    "                        raw_rate_seq[i_L,i_coh,i_t], skr_seq[i_L,i_coh,i_t], Fe2e_seq[i_L,i_coh,i_t] = T_sequential_cutoff(τ_cut,τ_coh, mu_link, F_link, Ls)\n",
    "                        if isnan(skr_seq[i_L,i_coh,i_t]):\n",
    "                            skr_seq[i_L,i_coh,i_t] = 1e-20\n",
    "\n",
    "                     # \"\"\"for parallel scheme\"\"\"\n",
    "                    if parallel_scheme_flag:\n",
    "                        if parallel_with_cutoff_flag:\n",
    "                            raw_rate_par[i_L,i_coh,i_t], skr_par[i_L,i_coh,i_t], Fe2e_par[i_L,i_coh,i_t] = T_parallel_cutoff(τ_cut,τ_coh, mu_link, F_link, Ls)\n",
    "                            if isnan(skr_par[i_L,i_coh,i_t]):\n",
    "                                skr_par[i_L,i_coh,i_t] = 1e-20\n",
    "        \n",
    "                if sequential_scheme:\n",
    "                    idx = np.argmax(skr_seq[i_L,i_coh,:])\n",
    "                    # print(idx)\n",
    "                    # print(skr_seq[i_coh,:])\n",
    "                    skr_seq_opt[i_L,i_coh] = skr_seq[i_L,i_coh,idx]\n",
    "                    raw_rate_seq_opt[i_L,i_coh] = raw_rate_seq[i_L,i_coh,idx]\n",
    "                    Fe2e_seq_opt[i_L,i_coh] = Fe2e_seq[i_L,i_coh,idx]\n",
    "                    \n",
    "                    τ_cut_opt[i_L,i_coh] = τ_cut_list[idx]\n",
    "                    \n",
    "                    raw_rate_seq_no_cut, skr_seq_no_cut[i_L,i_coh], _ = T_sequential_no_cutoff(τ_coh, mu_link, F_link, Ls)\n",
    "\n",
    "\n",
    "               \n",
    "                if parallel_scheme_flag:\n",
    "                    if parallel_with_cutoff_flag:\n",
    "                        idx = np.argmax(skr_par[i_L,i_coh,:])\n",
    "                        # print(idx)\n",
    "                        # print(skr_seq[i_coh,:])\n",
    "                        skr_par_opt[i_L,i_coh] = skr_par[i_L,i_coh,idx]\n",
    "                        raw_rate_par_opt[i_L,i_coh] = raw_rate_par[i_L,i_coh,idx]\n",
    "                        Fe2e_par_opt[i_L,i_coh] = Fe2e_par[i_L,i_coh,idx]\n",
    "                        \n",
    "                        τ_cut_opt[i_L,i_coh] = τ_cut_list[idx]\n",
    "                    raw_rate_par_no_cut, skr_par_no_cut[i_L,i_coh], _ = T_parallel_no_cutoff(τ_coh, mu_link, F_link, Ls)\n",
    "               \n",
    "        \n",
    "        if sequential_scheme:\n",
    "            x_values = []\n",
    "            y_values = []\n",
    "            each_L_not_feasible_coherence_values = {}\n",
    "            for i_L, Le2e in enumerate(Le2e_list):\n",
    "                Ls = [Le2e/n]*n\n",
    "                τ_cut_list = np.logspace(-0.5,2,num_τ)*Ls[0]/c/2 # cutoff [sec]\n",
    "                \n",
    "                # print(i_L, end='\\r')\n",
    "                exist_non_zero_skr_coherence_time  =False\n",
    "                for i_coh, τ_coh in enumerate(τ_coh_list):\n",
    "                    # if F_link==0.99 and mu_link==0.99 and (Le2e==400 or Le2e==400.0):\n",
    "                    #     print(i_coh,τ_coh,skr_seq_opt[i_L,i_coh])\n",
    "                    if skr_seq_opt[i_L,i_coh] == 1e-20 or skr_seq_opt[i_L,i_coh]<=0:\n",
    "                        #print(\"for L %s for i_coh %s we have infeasible skr\"%(Le2e,τ_coh))\n",
    "                        try:\n",
    "                            each_L_not_feasible_coherence_values[Le2e].append(i_coh)\n",
    "                        except:\n",
    "                            each_L_not_feasible_coherence_values[Le2e] = [i_coh]\n",
    "                    else:\n",
    "                        if not exist_non_zero_skr_coherence_time:\n",
    "                            exist_non_zero_skr_coherence_time = True\n",
    "                            minimum_non_zero_skr_coherence_time = i_coh\n",
    "               \n",
    "                target_coherece_value = -1\n",
    "                if exist_non_zero_skr_coherence_time:\n",
    "                    x_values.append(τ_coh_list[minimum_non_zero_skr_coherence_time])\n",
    "                    y_values.append(Le2e)\n",
    "                    target_coherece_value = τ_coh_list[minimum_non_zero_skr_coherence_time]\n",
    "                    # print(\"for x-axis %s we set y-axis %s \"%(target_coherece_value,Le2e))\n",
    "                    # if F_link==0.99 and mu_link==0.99 and (Le2e==400 or Le2e==400.0):\n",
    "                    #     print(\"2 we set for Le2e=400\",τ_coh_list[minimum_non_zero_skr_coherence_time])\n",
    "                # else:\n",
    "                #     if τ_coh_list[max(each_L_not_feasible_coherence_values[Le2e])]==max(τ_coh_list):\n",
    "                #         x_values.append(τ_coh_list[max(each_L_not_feasible_coherence_values[Le2e])])\n",
    "                #         y_values.append(Le2e)\n",
    "                #         target_coherece_value = τ_coh_list[max(each_L_not_feasible_coherence_values[Le2e])]\n",
    "                         \n",
    "                #     else:\n",
    "                #         x_values.append(τ_coh_list[max(each_L_not_feasible_coherence_values[Le2e])+1])\n",
    "                #         target_coherece_value = τ_coh_list[max(each_L_not_feasible_coherence_values[Le2e])+1]\n",
    "                # print(\"for x-axis %s we set y-axis %s \"%(target_coherece_value,Le2e))\n",
    "                \n",
    "                \n",
    "                    \n",
    "        \n",
    "            x_values_no_cutoff = []\n",
    "            y_values_no_cutoff = []\n",
    "            each_L_not_feasible_coherence_values_no_cutoff = {}\n",
    "            for i_L, Le2e in enumerate(Le2e_list):\n",
    "                Ls = [Le2e/n]*n\n",
    "                τ_cut_list = np.logspace(-0.5,2,num_τ)*Ls[0]/c/2 # cutoff [sec]\n",
    "                # print(i_L, end='\\r')\n",
    "                exist_non_zero_skr_coherence_time  =False\n",
    "                for i_coh, τ_coh in enumerate(τ_coh_list):\n",
    "                    if isnan(skr_seq_no_cut[i_L,i_coh]) or skr_seq_no_cut[i_L,i_coh]<=0:\n",
    "                        #print(\"for L %s for i_coh %s we have infeasible skr\"%(Le2e,τ_coh))\n",
    "                        try:\n",
    "                            each_L_not_feasible_coherence_values_no_cutoff[Le2e].append(i_coh)\n",
    "                        except:\n",
    "                            each_L_not_feasible_coherence_values_no_cutoff[Le2e] = [i_coh]\n",
    "                    else:\n",
    "                        if not exist_non_zero_skr_coherence_time:\n",
    "                            exist_non_zero_skr_coherence_time = True\n",
    "                            minimum_non_zero_skr_coherence_time = i_coh\n",
    "                if exist_non_zero_skr_coherence_time:\n",
    "                    y_values_no_cutoff.append(Le2e)\n",
    "                    x_values_no_cutoff.append(τ_coh_list[minimum_non_zero_skr_coherence_time])\n",
    "                \n",
    "\n",
    "        # \"\"\"for parallel scheme\"\"\"\n",
    "        if parallel_scheme_flag:\n",
    "            if parallel_with_cutoff_flag:\n",
    "                par_x_values = []\n",
    "                par_y_values = []\n",
    "                par_each_L_not_feasible_coherence_values = {}\n",
    "                for i_L, Le2e in enumerate(Le2e_list):\n",
    "                    Ls = [Le2e/n]*n\n",
    "                    τ_cut_list = np.logspace(-0.5,2,num_τ)*Ls[0]/c/2 # cutoff [sec]\n",
    "                    exist_non_zero_skr_coherence_time  =False\n",
    "                    # print(i_L, end='\\r')\n",
    "                    for i_coh, τ_coh in enumerate(τ_coh_list):\n",
    "                        if skr_par_opt[i_L,i_coh] == 1e-20 or skr_par_opt[i_L,i_coh]<=0:\n",
    "                            #print(\"for L %s for i_coh %s we have infeasible skr\"%(Le2e,τ_coh))\n",
    "                            try:\n",
    "                                par_each_L_not_feasible_coherence_values[Le2e].append(i_coh)\n",
    "                            except:\n",
    "                                par_each_L_not_feasible_coherence_values[Le2e] = [i_coh]\n",
    "                        else:\n",
    "                            if not exist_non_zero_skr_coherence_time:\n",
    "                                exist_non_zero_skr_coherence_time = True\n",
    "                                minimum_non_zero_skr_coherence_time = i_coh\n",
    "                    if exist_non_zero_skr_coherence_time:\n",
    "                        par_x_values.append(τ_coh_list[minimum_non_zero_skr_coherence_time])\n",
    "                        par_y_values.append(Le2e)\n",
    "                    \n",
    "            \n",
    "            par_x_values_no_cutoff = []\n",
    "            par_y_values_no_cutoff = []\n",
    "            par_each_L_not_feasible_coherence_values_no_cutoff = {}\n",
    "            for i_L, Le2e in enumerate(Le2e_list):\n",
    "                Ls = [Le2e/n]*n\n",
    "                τ_cut_list = np.logspace(-0.5,2,num_τ)*Ls[0]/c/2 # cutoff [sec]\n",
    "                # print(i_L, end='\\r')\n",
    "                exist_non_zero_skr_coherence_time  =False\n",
    "                for i_coh, τ_coh in enumerate(τ_coh_list):\n",
    "                    if isnan(skr_par_no_cut[i_L,i_coh]) or skr_par_no_cut[i_L,i_coh]<=0:\n",
    "                        #print(\"for L %s for i_coh %s we have infeasible skr\"%(Le2e,τ_coh))\n",
    "                        try:\n",
    "                            par_each_L_not_feasible_coherence_values_no_cutoff[Le2e].append(i_coh)\n",
    "                        except:\n",
    "                            par_each_L_not_feasible_coherence_values_no_cutoff[Le2e] = [i_coh]\n",
    "                    else:\n",
    "                        if not exist_non_zero_skr_coherence_time:\n",
    "                            exist_non_zero_skr_coherence_time = True\n",
    "                            minimum_non_zero_skr_coherence_time = i_coh\n",
    "                if exist_non_zero_skr_coherence_time:\n",
    "                    par_y_values_no_cutoff.append(Le2e)\n",
    "                    par_x_values_no_cutoff.append(τ_coh_list[minimum_non_zero_skr_coherence_time])\n",
    "                    \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # x_values_no_cutoff.sort()\n",
    "        if sequential_scheme:\n",
    "            for indx,τ_coh_value in enumerate(x_values_no_cutoff):\n",
    "                Le2e_value = y_values_no_cutoff[indx]\n",
    "                try:\n",
    "                    each_scheme_scheme_point_value[\"W/o cutoff,F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link)][τ_coh_value] =Le2e_value \n",
    "                except:\n",
    "                    each_scheme_scheme_point_value[\"W/o cutoff,F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link)]={}\n",
    "                    each_scheme_scheme_point_value[\"W/o cutoff,F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link)][τ_coh_value] =Le2e_value\n",
    "            # x_values.sort()\n",
    "            for indx,τ_coh_value in enumerate(x_values):\n",
    "                Le2e_value = y_values[indx]\n",
    "                try:\n",
    "                    each_scheme_scheme_point_value[\"F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link)][τ_coh_value] =Le2e_value \n",
    "                except:\n",
    "                    each_scheme_scheme_point_value[\"F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link)]={}\n",
    "                    each_scheme_scheme_point_value[\"F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link)][τ_coh_value] =Le2e_value\n",
    "            if \"F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link) not in selected_scheme_keys:\n",
    "                selected_scheme_keys.append(\"F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link))\n",
    "            if \"W/o cutoff,F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link) not in selected_scheme_keys:\n",
    "                selected_scheme_keys.append(\"W/o cutoff,F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link))\n",
    "\n",
    "        if parallel_scheme_flag:\n",
    "            # par_x_values_no_cutoff.sort()\n",
    "            for indx,τ_coh_value in enumerate(par_x_values_no_cutoff):\n",
    "                Le2e_value = par_y_values_no_cutoff[indx]\n",
    "                try:\n",
    "                    each_scheme_scheme_point_value[\"W/o cutoff,F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link)][τ_coh_value] =Le2e_value \n",
    "                except:\n",
    "                    each_scheme_scheme_point_value[\"W/o cutoff,F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link)]={}\n",
    "                    each_scheme_scheme_point_value[\"W/o cutoff,F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link)][τ_coh_value] =Le2e_value\n",
    "            if parallel_with_cutoff_flag:\n",
    "                # par_x_values.sort()\n",
    "                for indx,τ_coh_value in enumerate(par_x_values):\n",
    "                    Le2e_value = par_y_values[indx]\n",
    "                    try:\n",
    "                        each_scheme_scheme_point_value[\"F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link)][τ_coh_value] =Le2e_value \n",
    "                    except:\n",
    "                        each_scheme_scheme_point_value[\"F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link)]={}\n",
    "                        each_scheme_scheme_point_value[\"F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link)][τ_coh_value] =Le2e_value\n",
    "                if \"F=\"+str(F_link)+\", \"+\",mu=\"+str(mu_link) not in selected_scheme_keys:\n",
    "                    selected_scheme_keys.append(\"F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link))\n",
    "            if \"W/o cutoff,F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link) not in selected_scheme_keys:\n",
    "                selected_scheme_keys.append(\"W/o cutoff,F=\"+str(F_link)+\", \"+r'$\\mu$='+str(mu_link))\n",
    "\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        duration = end_time-start_time\n",
    "        print(\"F_link %s mu_link %s took %s minutes\"%(F_link,mu_link,duration/60),end= \"\\r\")\n",
    "        \n",
    "        \n",
    "        # plt.figure(figsize=(4.2,3))\n",
    "        # plt.xlabel(\"feasiblility coherence time [s]\")\n",
    "        # plt.ylabel(\"End-to-end distance [km]\")\n",
    "        # plt.plot(x_values,y_values,\"-\",linewidth=2.5,color=\"C0\",label = \"Seq,with cutoff\")\n",
    "        # plt.plot(x_values_no_cutoff,y_values_no_cutoff,\"-\",linewidth=2.5,color=\"C1\",label = \"Seq,no cutoff\")\n",
    "        # plt.legend(fontsize=12,handlelength=1.0,bbox_to_anchor=(0.36, 0.43))\n",
    "\n",
    "        # plt.xscale(\"log\")\n",
    "        # plt.savefig(\"../plotting/plots/figure3.2.1.pdf\")\n",
    "\n",
    "\n",
    "        \n",
    "                \n",
    "        # from matplotlib import cm\n",
    "        # import matplotlib.cbook as cbook\n",
    "        # import matplotlib.colors as colors\n",
    "        # from matplotlib.ticker import LinearLocator\n",
    "        \n",
    "        # # fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "        \n",
    "        # # Make data.\n",
    "        # X, Y = np.meshgrid(τ_coh_list, Le2e_list)\n",
    "        # # Z = skr_seq_opt\n",
    "        # # # Plot the surface.\n",
    "        # # surf = ax.plot_surface(X, Y, skr_seq_no_cut, cmap=cm.coolwarm,\n",
    "        # #                        linewidth=0, antialiased=False)\n",
    "        \n",
    "        # # ax.view_init(azim=0, elev=90)\n",
    "        # # plt.pcolor(X, Y, np.log(skr_seq_no_cut), cmap='viridis', vmin=1e-5, vmax=5)\n",
    "        \n",
    "        # plt.figure(figsize=(4.2,3))\n",
    "        \n",
    "        # Z = τ_cut_opt*1e3\n",
    "        # pcm = plt.pcolor(X, Y, Z,norm=colors.LogNorm(vmin=1e-2, vmax=5),\n",
    "        #                    cmap='viridis', shading='auto')\n",
    "        # plt.colorbar(pcm, extend='max')\n",
    "        # # plt.colorbar()\n",
    "        # plt.ylabel(\"End-to-end distance [km]\")\n",
    "        # plt.xlabel(\"coherence time [s] F=\"+str(F_link)+\"\\mu=\"+str(mu_link)+\"(? cutoff)\")\n",
    "        # plt.xscale(\"log\")\n",
    "        \n",
    "        # plt.figure(figsize=(4,3))\n",
    "        # Z = skr_seq_opt\n",
    "        # pcm = plt.pcolor(X, Y, Z,norm=colors.LogNorm(vmin=1e-5, vmax=150),\n",
    "        #                    cmap='YlOrBr', shading='auto')\n",
    "        # plt.colorbar(pcm, extend='max')\n",
    "        # # plt.colorbar()\n",
    "        # plt.xscale(\"log\")\n",
    "        # plt.ylabel(\"End-to-end distance [km]\")\n",
    "        # plt.xlabel(\"coherence time [s] F=\"+str(F_link)+\"\\mu=\"+str(mu_link)+\" (optimal)\")\n",
    "        # plt.tight_layout()\n",
    "        \n",
    "        # plt.figure(figsize=(4,3))\n",
    "        # Z = skr_seq_no_cut\n",
    "        # pcm = plt.pcolor(X, Y, Z,norm=colors.LogNorm(vmin=1e-5, vmax=150),\n",
    "        #                    cmap='viridis', shading='auto')\n",
    "        # plt.colorbar(pcm, extend='max')\n",
    "        # # plt.colorbar()\n",
    "        # plt.xscale(\"log\")\n",
    "        # plt.ylabel(\"End-to-end distance [km]\")\n",
    "        # plt.xlabel(\"coherence time [s] F=\"+str(F_link)+\"\\mu=\"+str(mu_link)+\" (no cutoff)\")\n",
    "        # plt.tight_layout()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i_L 20 Le2e 81.60606060606061 F_link 1.0 mu_link 1.0 took 1.387850813070933 minutesss\n",
    "\n",
    "selected_scheme_keys = [\n",
    "    \n",
    "                        \"F=1.0, \"+r'$\\mu$'+\"=1.0\",\n",
    "                        \"W/o cutoff,F=1.0, \"+r'$\\mu$'+\"=1.0\",\n",
    "                       \"F=1.0, \"+r'$\\mu$'+\"=0.99\",\n",
    "                        \"W/o cutoff,F=1.0, \"+r'$\\mu$'+\"=0.99\",\n",
    "                       # \"Seq,W.C,F=1.0,mu=0.98\",\n",
    "                       # \"Seq,W.C,F=1.0,mu=0.97\",\n",
    "                    \n",
    "                        \"F=0.99, \"+r'$\\mu$'+\"=1.0\",\n",
    "                       \"W/o,F=0.99, \"+r'$\\mu$'+\"=1.0\",\n",
    "                        \"F=0.99, \"+r'$\\mu$'+\"=0.99\",\n",
    "                     \"W/o,F=0.99, \"+r'$\\mu$'+\"=0.99\",\n",
    "    \n",
    "                       ]\n",
    "\n",
    "legends_titles = [  \n",
    "    \n",
    "                       \"F=1.0, \"+r'$\\mu$'+\"=1.0\",\n",
    "                        \n",
    "                       \"F=1.0, \"+r'$\\mu$'+\"=0.99\",\n",
    "                     \n",
    "\n",
    "                     \n",
    "                        \"F=0.99, \"+r'$\\mu$'+\"=1.0\",\n",
    "\n",
    "                     \"F=0.99, \"+r'$\\mu$'+\"=0.99\",\n",
    "\n",
    "\n",
    "                   # \"F=1.0, \"+r'$\\mu$'+\"=1.0\",\n",
    "                   #      \"W/o cutoff,F=1.0, \"+r'$\\mu$'+\"=1.0\",\n",
    "                   #     \"F=1.0, \"+r'$\\mu$'+\"=0.99\",\n",
    "                   #      \"W/o cutoff,F=1.0, \"+r'$\\mu$'+\"=0.99\",\n",
    "                   #     # \"Seq,W.C,F=1.0,mu=0.98\",\n",
    "                   #     # \"Seq,W.C,F=1.0,mu=0.97\",\n",
    "                   #   \"F=0.99, \"+r'$\\mu$'+\"=0.99\",\n",
    "                   #   \"W/o,F=0.99, \"+r'$\\mu$'+\"=0.99\",\n",
    "                   #      \"F=0.99, \"+r'$\\mu$'+\"=1.0\",\n",
    "                   #     \"W/o,F=0.99, \"+r'$\\mu$'+\"=1.0\",\n",
    "                  \n",
    "                       ]\n",
    "colors = [\"black\",\"black\",\"C0\",\"C0\",\"C1\",\"C1\",\"C2\",\"C2\",\"C3\",\"C3\"]\n",
    "lines = [\"solid\",\"dashed\",\"solid\",\"dashed\",\"solid\",\"dashed\",\"solid\",\"dashed\"]\n",
    "# for scheme in selected_scheme_keys:\n",
    "#     for coh,value in each_scheme_scheme_point_value[scheme].items():\n",
    "#         print(coh,value)\n",
    "print(\"each_scheme_scheme_point_value\",each_scheme_scheme_point_value.keys() )\n",
    "# for item in τ_coh_list:\n",
    "#     print(item)\n",
    "\n",
    "for scheme,point_value in each_scheme_scheme_point_value.items():\n",
    "    for point,value in point_value.items():\n",
    "        with open(\"parallel_protocol_feasibility_results.csv\", 'a') as newFile:                                \n",
    "            newFileWriter = csv.writer(newFile)\n",
    "            newFileWriter.writerow([scheme,point,value])\n",
    "ploting_simple_y_as_x(\"coherence time [s]\",\"End-to-end distance [km]\",\n",
    "                        18, 18, 14,\n",
    "                      14, 0, 0,\n",
    "                      0,0,False,[],400,\n",
    "                      \n",
    "                      list(selected_scheme_keys),legends_titles,colors,lines,\n",
    "                      each_scheme_scheme_point_value,\n",
    "                      τ_coh_list,τ_coh_list,\n",
    "                      False,True,True,True,1,12,\n",
    "                      \"../plotting/plots/repeater_chains_feasibility_region_all_schmes_v2_parallel.pdf\",True,2,6.2,3.8,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_values)\n",
    "print(y_values)\n",
    "\n",
    "print(x_values_no_cutoff)\n",
    "print(y_values_no_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "\n",
    "for i_coh, τ_coh in enumerate(τ_coh_list):\n",
    "    plt.plot(τ_cut_list*1e3,skr_seq[i_coh,:],\"-\",color=f\"C{i_coh}\",label=f\"{τ_coh:0.3f}\")\n",
    "\n",
    "plt.plot(τ_cut_list*1e3,skr_seq[-1,:],\"-\")\n",
    "\n",
    "t0 = Ls[0]/c*1e3/Trans(Ls[0])\n",
    "# plt.plot([t0,t0],[0,4],\"k--\")\n",
    "\n",
    "# # for reference:\n",
    "# plt.plot(τ_cut_list*1e3,raw_rate_par_no_cut+0*τ_cut_list , \"-.\" ,color=\"C0\",label=\"raw rate par, no cutoff\")\n",
    "# plt.plot(τ_cut_list*1e3,raw_rate_seq_no_cut+0*τ_cut_list , \"-.\" ,color=\"C1\",label=\"raw rate seq, no cutoff\")\n",
    "# plt.plot(τ_cut_list*1e3,skr_par_no_cut+0*τ_cut_list , \".\", markersize=1 ,color=\"C0\",label=\"skr par, no cutoff\")\n",
    "# plt.plot(τ_cut_list*1e3,skr_seq_no_cut+0*τ_cut_list , \".\", markersize=1 ,color=\"C1\",label=\"skr seq, no cutoff\")\n",
    "\n",
    "plt.ylabel(r\"Rate $[ebit/s]$\")\n",
    "plt.xlabel(\"cut-off time [ms]\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(τ_coh_list*1e3, τ_cut_opt.T*1e3,\"o-\")\n",
    "plt.plot(τ_coh_list*1e3, skr_seq_opt.T,\"o-\")\n",
    "plt.plot(τ_coh_list*1e3, skr_seq_no_cut.T,\"k--\")\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "# skr_seq_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
